{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43be3784-59f3-49ce-99eb-a4163e216f7c",
   "metadata": {},
   "source": [
    "# Data extraction "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25fa38f9-f166-46ae-bfa5-b1a1ad75e64e",
   "metadata": {},
   "source": [
    "On this notebook I will extract the data from my zenodo database to only keep the exact documents ParlaMint uses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "790a0af7-74b0-45bc-a118-af03cafbe82f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: congreso in /Users/paula/anaconda3/lib/python3.11/site-packages (1.0.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install congreso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40426c43-4d55-4bec-9017-c57da1d35bd1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from congreso import congreso as c \n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "terms = [\"X\", \"XIV\", \"XIII\", \"XII\", \"XI\"]\n",
    "t = c.load_jsons(terms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aeb3589-6e37-4f56-aa00-53f880e9d5e6",
   "metadata": {},
   "source": [
    "Now that the data is extracted we just need to use some simple functions to be able to filter the documents on congreso.db. This filters will filter by year, diario de sesiones, section and finaly organ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01f06aa6-3d2a-48aa-b1a5-ec5735a4636d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def filter_DS_documents(term_dictionary):\n",
    "  DS_term = []\n",
    "  for doc in term_dictionary:\n",
    "    if doc[\"encabezado\"] == \"DS\":\n",
    "      DS_term.append(doc)\n",
    "  return DS_term\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9473a221-665d-4626-800c-cb80c8e6206b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def filter_docs(docs, year):\n",
    "    lowerbound = f\"{year}0101\"\n",
    "    upperbound = f\"{year}1231\"\n",
    "    # Filter documents based on the date range\n",
    "    docs = filter_DS_documents(c.get_documents_interval_dates(docs, lowerbound, upperbound))\n",
    "    \n",
    "    # Filter by section\n",
    "    filter_1 = []\n",
    "    for doc in docs:\n",
    "        if doc[\"secc\"] in [\"CONGRESO\", \"CONGRESO DE LOS DIPUTADOS\"]:\n",
    "            filter_1.append(doc)\n",
    "\n",
    "    # Filter by organization\n",
    "    filtered_docs = []\n",
    "    for doc in filter_1:\n",
    "        if doc[\"orga\"] == \"Pleno\":\n",
    "            filtered_docs.append(doc)\n",
    "\n",
    "    # Sort by date\n",
    "    filtered_docs = sorted(filtered_docs, key=lambda x: x['fecha'])\n",
    "    \n",
    "    # Return the filtered and sorted documents\n",
    "    return filtered_docs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b76127-e31d-40a9-a8fd-ea7743fe286f",
   "metadata": {
    "tags": []
   },
   "source": [
    "Finally, we now can get our filtered documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c32b6a9-1703-414a-85f7-9e559a7da4d8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No documents between 2016-01-01 and 2016-12-31 for the term X\n"
     ]
    }
   ],
   "source": [
    "d_2015 = filter_docs(t[\"X\"], \"2015\")\n",
    "\n",
    "d_2016_X = c.get_documents_interval_dates(t[\"X\"], \"20160101\", \"20161231\")\n",
    "d_2016_XI = c.get_documents_interval_dates(t[\"XI\"], \"20160101\", \"20161231\")\n",
    "d_2016_XII = c.get_documents_interval_dates(t[\"XII\"], \"20160101\", \"20161231\")\n",
    "docs_2016 = d_2016_XI + d_2016_XII + d_2016_X\n",
    "d_2016 = filter_docs(docs_2016, \"2016\")\n",
    "\n",
    "d_2017 = filter_docs(t[\"XII\"], \"2017\")\n",
    "\n",
    "d_2018 = filter_docs(t[\"XII\"], \"2018\")\n",
    "\n",
    "d_2019_XII = c.get_documents_interval_dates(t[\"XII\"], \"20190101\", \"20191231\")\n",
    "d_2019_XIII = c.get_documents_interval_dates(t[\"XIII\"], \"20190101\", \"20191231\")\n",
    "d_2019_XIV = c.get_documents_interval_dates(t[\"XIV\"], \"20190101\", \"20191231\")\n",
    "docs_2019 = d_2019_XII + d_2019_XIII + d_2019_XIV\n",
    "d_2019 = filter_docs(docs_2019, \"2019\")\n",
    "\n",
    "d_2020 = filter_docs(t[\"XIV\"], \"2020\")\n",
    "\n",
    "d_2021 = filter_docs(t[\"XIV\"], \"2021\")\n",
    "\n",
    "d_2022 = filter_docs(t[\"XIV\"], \"2022\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "023172d5-8c24-4ac8-970b-c4c25d2b8d3b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docs 2015 filtered = 57\n",
      "Docs 2016 filtered = 36\n",
      "Docs 2017 filtered = 70\n",
      "Docs 2018 filtered = 72\n",
      "Docs 2019 filtered = 19\n",
      "Docs 2020 filtered = 68\n",
      "Docs 2021 filtered = 76\n",
      "Docs 2022 filtered = 84\n"
     ]
    }
   ],
   "source": [
    "print(\"Docs 2015 filtered =\",c.num_docs_term(d_2015))\n",
    "print(\"Docs 2016 filtered =\",c.num_docs_term(d_2016))\n",
    "print(\"Docs 2017 filtered =\",c.num_docs_term(d_2017))\n",
    "\n",
    "\n",
    "print(\"Docs 2018 filtered =\",c.num_docs_term(d_2018))\n",
    "print(\"Docs 2019 filtered =\",c.num_docs_term(d_2019))\n",
    "print(\"Docs 2020 filtered =\",c.num_docs_term(d_2020))\n",
    "\n",
    "print(\"Docs 2021 filtered =\",c.num_docs_term(d_2021))\n",
    "print(\"Docs 2022 filtered =\",c.num_docs_term(d_2022))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79fdf7b-ff91-47bd-98b3-38e026b50c4e",
   "metadata": {},
   "source": [
    "Now I save the data in json format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cb1ff2a6-4820-43fd-9686-5b87194e0769",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: clean-data/d_2015.json\n",
      "Saved: clean-data/d_2016.json\n",
      "Saved: clean-data/d_2017.json\n",
      "Saved: clean-data/d_2018.json\n",
      "Saved: clean-data/d_2019.json\n",
      "Saved: clean-data/d_2020.json\n",
      "Saved: clean-data/d_2021.json\n",
      "Saved: clean-data/d_2022.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "dicts_by_year = {\n",
    "    2015: d_2015,\n",
    "    2016: d_2016,\n",
    "    2017: d_2017,\n",
    "    2018: d_2018,\n",
    "    2019: d_2019,\n",
    "    2020: d_2020,\n",
    "    2021: d_2021,\n",
    "    2022: d_2022\n",
    "}\n",
    "\n",
    "for year, doc_dict in dicts_by_year.items():\n",
    "    new_file = f\"clean-data/d_{year}.json\"\n",
    "    with open(new_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(doc_dict, f, ensure_ascii=False, indent=4)\n",
    "    print(f\"Saved: {new_file}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c61873cd-1ce3-4e29-90ce-4da68b6f8d4c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20190122\n"
     ]
    }
   ],
   "source": [
    "print(d_2019[0][\"fecha\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
